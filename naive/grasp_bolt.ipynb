{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyros as jr # optional - for jupyter dev only\n",
    "import ipyvolume as ipv # for pwointcloud visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import image_geometry as img_geo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pcl\n",
    "import pickle\n",
    "import rosbag\n",
    "import rospy\n",
    "import tf\n",
    "\n",
    "from pcl_helper import *\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from geometry_msgs.msg import PoseStamped\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "from sklearn.decomposition import PCA\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get an image\n",
    "from `bag` or `publisher`. provides an `rgb` image and an `mm` depthimage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = rosbag.Bag('../data/new_bin_with_screws2.bag', \"r\")\n",
    "bridge = CvBridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['/head_camera/rgb/image_raw', '/head_camera/depth_registered/image', '/head_camera/depth_registered/points']\n",
    "for topic, msg, _ in bag.read_messages(topics=topics):\n",
    "    if topic==topics[0]:\n",
    "        rgb_img = bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')\n",
    "    elif topic==topics[1]:\n",
    "        depth_img = bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')\n",
    "    else:\n",
    "        cloud = ros_to_pcl(msg)\n",
    "        pcl_msg = msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mask green\n",
    "to get bin outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_green, green_benchmark = None, 'green.pkl'\n",
    "if green_benchmark not in os.listdir('.'):\n",
    "    with open(green_benchmark, 'w') as f:\n",
    "        pickle.dump(green_benchmark, f)\n",
    "with open(green_benchmark, 'r') as f:\n",
    "    real_green = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_GREEN = np.mean(real_green, axis=0, dtype=int)\n",
    "STDEV = 2.5*np.std(real_green, axis=0).astype(int)\n",
    "ALPHA = 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_img = np.clip(rgb_img * ALPHA, 0, 255).astype(np.uint8)\n",
    "mask = cv2.inRange(hc_img, BIN_GREEN-STDEV, BIN_GREEN+STDEV)\n",
    "res = cv2.bitwise_and(hc_img, hc_img, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter only bolts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(res, cv2.COLOR_BGR2GRAY), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "_, contours, hierarchy = cv2.findContours(gray_img, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find convex hull of green bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_contour = contours[np.argmax([cv2.contourArea(c) for c in contours])]\n",
    "EPSILON = 0.1*cv2.arcLength(max_contour, True)\n",
    "hull = cv2.convexHull(cv2.approxPolyDP(max_contour, EPSILON, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res.copy(); plt.imshow(cv2.drawContours(res2, [max_contour], -1, (0,255,0), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a less dumb approach: RANSAC away flat planes in depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find dark blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT_RANGE = int(0.3 * (np.max(hull[:,:,1]) - np.min(hull[:,:,1])))\n",
    "WIDTH_RANGE = int(1.8 * HEIGHT_RANGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx, cy = np.mean(hull, axis=0)[0].astype(int)\n",
    "roi_origin = (cy-HEIGHT_RANGE), (cx-WIDTH_RANGE)\n",
    "roi = res[cy-HEIGHT_RANGE:cy+HEIGHT_RANGE,\\\n",
    "   cx-WIDTH_RANGE:cx+WIDTH_RANGE,:]\n",
    "roi[roi < np.array([50, 25, 50])] = 0 # threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "_, contours, hierarchy = cv2.findContours(gray_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = np.array([cv2.contourArea(c) for c in contours])\n",
    "mean_area = np.mean(areas)\n",
    "part_area = 0.6*mean_area\n",
    "MIN_AREA, MAX_AREA = mean_area-part_area, mean_area+2*part_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = np.where((areas>MIN_AREA) & (areas<MAX_AREA))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### singulate a bolt\n",
    "score = w * (dist from top of image + flatness of bounding box)\n",
    "\n",
    "(as measures of greatest operating volume for end-effector & top-down surface area of bolt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(contour):\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = np.int0(cv2.boxPoints(rect))\n",
    "    x, y = np.mean(box[:,0]), np.mean(box[:,1])\n",
    "    _, _, angle = cv2.fitEllipse(contour)\n",
    "    return int(x), int(y), angle, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x, y, angle):\n",
    "    dist_from_normal = abs((90.0-angle)/180.0)\n",
    "    return y/480.0 + (1-dist_from_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities, meta = [], []\n",
    "fig, ax = plt.subplots(figsize=(30,10), nrows=2, ncols=3)\n",
    "for i, candidate in enumerate(candidates):\n",
    "    x, y, angle, box = bounding_box(contours[candidate])\n",
    "    entities.append(box)\n",
    "    meta.append((x, y, angle))\n",
    "    res2 = roi.copy()\n",
    "    ax.flat[i].imshow(cv2.drawContours(res2, [entities[-1]], 0, (0, 255, 0), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(x, y, z)` give 3D pose wrt camera frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_TABLE_HEIGHT = np.inf # unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_best = np.argmax([score(x, y, angle) for (x, y, angle) in meta])\n",
    "x = int(meta[i_best][1] + roi_origin[0])\n",
    "y = int(meta[i_best][0] + roi_origin[1])\n",
    "z = min(depth_img[x, y], K_TABLE_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5), nrows=1, ncols=2)\n",
    "ax[0].imshow(rgb_img[x-50:x+50, y-50:y+50])\n",
    "ax[1].imshow(depth_img[x-50:x+50, y-50:y+50], cmap='gray')\n",
    "for axes in ax:\n",
    "    axes.plot(50, 50, 'o', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you must run `roscore` first\n",
    "\n",
    "publish a `tf` to get the correct transforms\n",
    "\n",
    "only run `init_node` once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node('test')\n",
    "while not rospy.Time.now():\n",
    "    pass\n",
    "import time; time.sleep(5) # hotfix to let TF buffer fill\n",
    "tfl = tf.TransformListener()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO make `camera` a class field, so `xyz_to_pose` can grab it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = img_geo.PinholeCameraModel() \n",
    "camera.fromCameraInfo(rospy.wait_for_message('/head_camera/depth/camera_info', CameraInfo))\n",
    "frame_x, frame_y, _ = camera.projectPixelTo3dRay((x, y))\n",
    "frame_z = z/1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes a top-down grasp\n",
    "def xyz_to_pose(x, y, z, yaw=np.radians(90), src_frame='/base_link', dst_frame='/head_camera_rgb_optical_frame'):\n",
    "    pose = PoseStamped()\n",
    "    pose.header.frame_id = dst_frame\n",
    "    pose.header.stamp = tfl.getLatestCommonTime(src_frame, dst_frame) #rospy.Time.now()\n",
    "    pose.pose.position.x = x\n",
    "    pose.pose.position.y = y\n",
    "    pose.pose.position.z = z if z<=1000.0 else z/1000.0 # max depth range 1 meter\n",
    "    pose.pose.orientation.w = 1.0\n",
    "    tfl.waitForTransform(camera.tfFrame(), src_frame, tfl.getLatestCommonTime(src_frame, dst_frame), rospy.Duration(5.0))\n",
    "    target = tfl.transformPose(src_frame, pose)\n",
    "    \n",
    "    # make top-down\n",
    "    q = tf.transformations.quaternion_from_euler(np.radians(180), np.radians(90), yaw)\n",
    "    target.pose.orientation.x = q[0]\n",
    "    target.pose.orientation.y = q[1]\n",
    "    target.pose.orientation.z = q[2]\n",
    "    target.pose.orientation.w = q[3]\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_x, frame_y, frame_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = xyz_to_pose(frame_x, frame_y, frame_z, yaw=np.radians(90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_pcl(X, color='red'):\n",
    "    N = X.T\n",
    "    if type(X)!='numpy.ndarray':\n",
    "        N = np.asarray(X).T\n",
    "    ipv.figure()\n",
    "    ipv.quickscatter(N[0,], N[1,], N[2,], size=1, marker='point_2d', color=color)\n",
    "    ipv.xyzlim(-1.0, 1.5)\n",
    "    ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.radians(56)\n",
    "T = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, np.cos(theta), -np.sin(theta), 0],\n",
    "    [0, np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "X = np.dot(cloud.to_array(), T)\n",
    "X = XYZRGB_to_XYZ(X)\n",
    "#view_pcl(np.asarray(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out most of table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_HEIGHT = (0.0, 0.7) # 0.6\n",
    "TABLE_DEPTH = (0.0, 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_axis, passthrough = 'y', X.make_passthrough_filter()\n",
    "passthrough.set_filter_field_name('y')\n",
    "passthrough.set_filter_limits(*TABLE_HEIGHT)\n",
    "passthrough = passthrough.filter().make_passthrough_filter()\n",
    "passthrough.set_filter_field_name('z')\n",
    "passthrough.set_filter_limits(*TABLE_DEPTH)\n",
    "X = passthrough.filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372f1eb914f24173a412d65929f4e7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VkJveChjaGlsZHJlbj0oRmlndXJlKGNhbWVyYT1QZXJzcGVjdGl2ZUNhbWVyYShmb3Y9NDYuMCwgcG9zaXRpb249KDAuMCwgMC4wLCAyLjApLCBxdWF0ZXJuaW9uPSgwLjAsIDAuMCwgMC4wLCDigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_pcl(X.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = X.make_segmenter()\n",
    "seg.set_model_type(pcl.SACMODEL_PLANE)\n",
    "seg.set_method_type(pcl.SAC_RANSAC)\n",
    "max_distance = 0.01\n",
    "seg.set_distance_threshold(max_distance)\n",
    "\n",
    "# Extract inliers and outliers\n",
    "inliers, coefficients = seg.segment()\n",
    "table = X.extract(inliers, negative=False)\n",
    "objects = X.extract(inliers, negative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d46ed55864a4aff890467b57fee380a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VkJveChjaGlsZHJlbj0oRmlndXJlKGNhbWVyYT1QZXJzcGVjdGl2ZUNhbWVyYShmb3Y9NDYuMCwgcG9zaXRpb249KDAuMCwgMC4wLCAyLjApLCBxdWF0ZXJuaW9uPSgwLjAsIDAuMCwgMC4wLCDigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_pcl(np.asarray(objects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get ground truth (bolt) pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt_truth = pcl.load('../data/bolt.pcd')\n",
    "voxels = bolt_truth.make_voxel_grid_filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAF_SIZE = 1.0\n",
    "voxels.set_leaf_size(LEAF_SIZE, LEAF_SIZE, LEAF_SIZE)\n",
    "bolt_truth = voxels.filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize for our camera frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUTH_SCALE = 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a3315f754d4045a6c98befb72ac303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VkJveChjaGlsZHJlbj0oRmlndXJlKGNhbWVyYT1QZXJzcGVjdGl2ZUNhbWVyYShmb3Y9NDYuMCwgcG9zaXRpb249KDAuMCwgMC4wLCAyLjApLCBxdWF0ZXJuaW9uPSgwLjAsIDAuMCwgMC4wLCDigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled = np.asarray(bolt_truth).T.copy()/TRUTH_SCALE\n",
    "bolt_truth = pcl.PointCloud(scaled.T)\n",
    "ipv.figure()\n",
    "ipv.quickscatter(scaled[0,], scaled[1,], scaled[2,], size=1, marker='sphere', color='blue')\n",
    "ipv.xyzlim(0,0.2)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### euclidean clustering\n",
    "find big blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_SIZE = 0.01\n",
    "MIN_CLUSTER, MAX_CLUSTER = 400, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = objects.make_kdtree()\n",
    "ec = objects.make_EuclideanClusterExtraction()\n",
    "ec.set_ClusterTolerance(CLUSTER_SIZE)\n",
    "ec.set_MinClusterSize(MIN_CLUSTER)\n",
    "ec.set_MaxClusterSize(MAX_CLUSTER)\n",
    "ec.set_SearchMethod(tree)\n",
    "cluster_indices = ec.Extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "for j, indices in enumerate(cluster_indices):\n",
    "    points = np.zeros((len(indices), 3), dtype=np.float32)\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        points[i][0] = objects[index][0]\n",
    "        points[i][1] = objects[index][1]\n",
    "        points[i][2] = objects[index][2]\n",
    "\n",
    "    cluster = pcl.PointCloud()\n",
    "    cluster.from_array(points)\n",
    "    clusters.append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d18f51607443f9b7a6fdc5b41b11ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VkJveChjaGlsZHJlbj0oRmlndXJlKGNhbWVyYT1QZXJzcGVjdGl2ZUNhbWVyYShmb3Y9NDYuMCwgcG9zaXRpb249KDAuMCwgMC4wLCAyLjApLCBxdWF0ZXJuaW9uPSgwLjAsIDAuMCwgMC4wLCDigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.figure()\n",
    "N = np.asarray(objects).T\n",
    "ipv.scatter(N[0,], N[1,], N[2,], size=2, marker='point_2d', color='red')\n",
    "ipv.xyzlim(-0.4, 0.8)\n",
    "\n",
    "for cluster in clusters:\n",
    "    N = np.asarray(cluster).T\n",
    "    ipv.scatter(N[0,], N[1,], N[2,], size=3, marker='point_2d', color='blue')\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICP\n",
    "minimize dissimilarity b/w ground truth bolt and any blob,\n",
    "return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = clusters[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/.local/lib/python2.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Non length-one string passed in for the array ordering. Please pass in 'C', 'F', 'A', or 'K' instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "target = pcl.PointCloud(np.array(target).astype(np.float32))\n",
    "icp = bolt_truth.make_IterativeClosestPoint()\n",
    "converged, transf, estimate, fitness = icp.icp(bolt_truth, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform back to original depth camera frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04175097,  0.05268445,  0.75619031])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_cluster = np.dot(target, np.linalg.inv(T[:3,:3]))\n",
    "np.mean(orig_cluster, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all transformations & registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23753771, -0.02622684,  0.9710252 ],\n",
       "       [-0.5075893 ,  0.84895104,  0.14709911],\n",
       "       [-0.8282101 , -0.5278231 ,  0.1883448 ]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transf[:3,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICP fails\n",
    "although $ T^{truth}_{target} $ is accurate, noise causes a match that may result in a failing grasp. we should ignore priors from the existing bolt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1683505c6043d4b0a18a8695c57a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VkJveChjaGlsZHJlbj0oRmlndXJlKGNhbWVyYT1QZXJzcGVjdGl2ZUNhbWVyYShmb3Y9NDYuMCwgcG9zaXRpb249KDAuMCwgMC4wLCAyLjApLCBxdWF0ZXJuaW9uPSgwLjAsIDAuMCwgMC4wLCDigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipv.figure()\n",
    "#N = np.asarray(clusters[5]).T\n",
    "#ipv.scatter(N[0,], N[1,], N[2,], size=1, marker='sphere', color='blue')\n",
    "#N = np.asarray(objects).T\n",
    "#ipv.scatter(N[0,], N[1,], N[2,], size=2, marker='point_2d', color='yellow')\n",
    "\n",
    "N = np.asarray(orig_cluster).T\n",
    "ipv.scatter(N[0,], N[1,], N[2,], size=1, marker='sphere', color='blue')\n",
    "N = np.asarray(cloud).T\n",
    "ipv.scatter(N[0,], N[1,], N[2,], size=2, marker='point_2d', color='red')\n",
    "\n",
    "N = np.asarray(bolt_truth).T\n",
    "ipv.scatter(N[0,], N[1,], N[2,], size=1, marker='sphere', color='yellow')\n",
    "N = np.dot(np.asarray(bolt_truth), transf[:3,:3]).T\n",
    "ipv.scatter(N[0,], N[1,], N[2,], size=1, marker='sphere', color='blue')\n",
    "\n",
    "#N = np.asarray(estimate).T\n",
    "#ipv.scatter(N[0,], N[1,], N[2,], size=3, marker='point_2d', color='blue')\n",
    "ipv.xyzlim(-0.4, 0.8)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06190419,  0.6482394 ,  0.39089406],\n",
       "       [-0.06046522,  0.6482394 ,  0.39089406],\n",
       "       [-0.05902625,  0.6482394 ,  0.39089406],\n",
       "       ...,\n",
       "       [-0.0575111 ,  0.6626961 ,  0.3676728 ],\n",
       "       [-0.05607403,  0.6626961 ,  0.3676728 ],\n",
       "       [-0.05470932,  0.66357386,  0.3681598 ]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04175099,  0.6563714 ,  0.3791789 ], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=3, copy=True)\n",
    "pca.fit(np.asarray(target))\n",
    "pca.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vector(v0, v1, v2, ax=None):\n",
    "    ax = ax or plt.figure().add_subplot(111, projection='3d')\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1[:2], v0[:2], arrowprops=arrowprops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
