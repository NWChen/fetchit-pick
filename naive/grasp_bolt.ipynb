{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyros as jr # optional - for jupyter dev only\n",
    "import ipyvolume as ipv # for pointcloud visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import image_geometry as img_geo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import rosbag\n",
    "import rospy\n",
    "import tf\n",
    "\n",
    "from pcl_helper import *\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "from geometry_msgs.msg import PoseStamped\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get an image\n",
    "from `bag` or `publisher`. provides an `rgb` image and an `mm` depthimage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = rosbag.Bag('../data/new_bin_with_screws.bag', \"r\")\n",
    "bridge = CvBridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['/head_camera/rgb/image_raw', '/head_camera/depth_registered/image', '/head_camera/depth_registered/points']\n",
    "for topic, msg, _ in bag.read_messages(topics=topics):\n",
    "    if topic==topics[0]:\n",
    "        rgb_img = bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')\n",
    "    elif topic==topics[1]:\n",
    "        depth_img = bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')\n",
    "    else:\n",
    "        cloud = ros_to_pcl(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_pcl(cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get image from `publisher` in current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img, depth_img = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_callback(data):\n",
    "    rgb_img = data\n",
    "\n",
    "def depth_callback(data):\n",
    "    depth_img = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_sub = rospy.Subscriber(topics[0], Image, rgb_callback)\n",
    "depth_sub = rospy.Subscriber(topics[1], Image, depth_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mask green\n",
    "to get bin outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_green, green_benchmark = None, 'green.pkl'\n",
    "if green_benchmark not in os.listdir('.'):\n",
    "    with open(green_benchmark, 'w') as f:\n",
    "        pickle.dump(green_benchmark, f)\n",
    "with open(green_benchmark, 'r') as f:\n",
    "    real_green = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_GREEN = np.mean(real_green, axis=0, dtype=int)\n",
    "STDEV = 2.5*np.std(real_green, axis=0).astype(int)\n",
    "ALPHA = 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_img = np.clip(rgb_img * ALPHA, 0, 255).astype(np.uint8)\n",
    "mask = cv2.inRange(hc_img, BIN_GREEN-STDEV, BIN_GREEN+STDEV)\n",
    "res = cv2.bitwise_and(hc_img, hc_img, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter only bolts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(res, cv2.COLOR_BGR2GRAY), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "_, contours, hierarchy = cv2.findContours(gray_img, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find convex hull of green bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_contour = contours[np.argmax([cv2.contourArea(c) for c in contours])]\n",
    "EPSILON = 0.1*cv2.arcLength(max_contour, True)\n",
    "hull = cv2.convexHull(cv2.approxPolyDP(max_contour, EPSILON, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res.copy(); plt.imshow(cv2.drawContours(res2, [max_contour], -1, (0,255,0), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a less dumb approach: RANSAC away flat planes in depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find dark blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT_RANGE = int(0.3 * (np.max(hull[:,:,1]) - np.min(hull[:,:,1])))\n",
    "WIDTH_RANGE = int(1.8 * HEIGHT_RANGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx, cy = np.mean(hull, axis=0)[0].astype(int)\n",
    "roi_origin = (cy-HEIGHT_RANGE), (cx-WIDTH_RANGE)\n",
    "roi = res[cy-HEIGHT_RANGE:cy+HEIGHT_RANGE,\\\n",
    "   cx-WIDTH_RANGE:cx+WIDTH_RANGE,:]\n",
    "roi[roi < np.array([50, 25, 50])] = 0 # threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "_, contours, hierarchy = cv2.findContours(gray_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = np.array([cv2.contourArea(c) for c in contours])\n",
    "mean_area = np.mean(areas)\n",
    "part_area = 0.6*mean_area\n",
    "MIN_AREA, MAX_AREA = mean_area-part_area, mean_area+2*part_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = np.where((areas>MIN_AREA) & (areas<MAX_AREA))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### singulate a bolt\n",
    "score = w * (dist from top of image + flatness of bounding box)\n",
    "\n",
    "(as measures of greatest operating volume for end-effector & top-down surface area of bolt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(contour):\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    box = np.int0(cv2.boxPoints(rect))\n",
    "    x, y = np.mean(box[:,0]), np.mean(box[:,1])\n",
    "    _, _, angle = cv2.fitEllipse(contour)\n",
    "    return int(x), int(y), angle, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x, y, angle):\n",
    "    dist_from_normal = abs((90.0-angle)/180.0)\n",
    "    return y/480.0 + (1-dist_from_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities, meta = [], []\n",
    "fig, ax = plt.subplots(figsize=(30,10), nrows=2, ncols=3)\n",
    "for i, candidate in enumerate(candidates):\n",
    "    x, y, angle, box = bounding_box(contours[candidate])\n",
    "    entities.append(box)\n",
    "    meta.append((x, y, angle))\n",
    "    res2 = roi.copy()\n",
    "    ax.flat[i].imshow(cv2.drawContours(res2, [entities[-1]], 0, (0, 255, 0), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(x, y, z)` give 3D pose wrt camera frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_TABLE_HEIGHT = np.inf # unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_best = np.argmax([score(x, y, angle) for (x, y, angle) in meta])\n",
    "x = int(meta[i_best][1] + roi_origin[0])\n",
    "y = int(meta[i_best][0] + roi_origin[1])\n",
    "z = min(depth_img[x, y], K_TABLE_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5), nrows=1, ncols=2)\n",
    "ax[0].imshow(rgb_img[x-50:x+50, y-50:y+50])\n",
    "ax[1].imshow(depth_img[x-50:x+50, y-50:y+50], cmap='gray')\n",
    "for axes in ax:\n",
    "    axes.plot(50, 50, 'o', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you must run `roscore` first\n",
    "\n",
    "publish a `tf` to get the correct transforms\n",
    "\n",
    "only run `init_node` once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node('test')\n",
    "while not rospy.Time.now():\n",
    "    pass\n",
    "import time; time.sleep(5) # hotfix to let TF buffer fill\n",
    "tfl = tf.TransformListener()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO make `camera` a class field, so `xyz_to_pose` can grab it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = img_geo.PinholeCameraModel() \n",
    "camera.fromCameraInfo(rospy.wait_for_message('/head_camera/depth/camera_info', CameraInfo))\n",
    "frame_x, frame_y, _ = camera.projectPixelTo3dRay((x, y))\n",
    "frame_z = z/1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes a top-down grasp\n",
    "def xyz_to_pose(x, y, z, yaw=np.radians(90), src_frame='/base_link', dst_frame='/head_camera_rgb_optical_frame'):\n",
    "    pose = PoseStamped()\n",
    "    pose.header.frame_id = dst_frame\n",
    "    pose.header.stamp = tfl.getLatestCommonTime(src_frame, dst_frame) #rospy.Time.now()\n",
    "    pose.pose.position.x = x\n",
    "    pose.pose.position.y = y\n",
    "    pose.pose.position.z = z if z<=1000.0 else z/1000.0 # max depth range 1 meter\n",
    "    pose.pose.orientation.w = 1.0\n",
    "    tfl.waitForTransform(camera.tfFrame(), src_frame, tfl.getLatestCommonTime(src_frame, dst_frame), rospy.Duration(5.0))\n",
    "    target = tfl.transformPose(src_frame, pose)\n",
    "    \n",
    "    # make top-down\n",
    "    q = tf.transformations.quaternion_from_euler(np.radians(180), np.radians(90), yaw)\n",
    "    target.pose.orientation.x = q[0]\n",
    "    target.pose.orientation.y = q[1]\n",
    "    target.pose.orientation.z = q[2]\n",
    "    target.pose.orientation.w = q[3]\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_x, frame_y, frame_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = xyz_to_pose(frame_x, frame_y, frame_z, yaw=np.radians(90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_pcl(X, theta=0):\n",
    "    N = X.T\n",
    "    if type(X)!='numpy.ndarray':\n",
    "        N = np.asarray(X).T\n",
    "    ipv.figure()\n",
    "    ipv.quickscatter(N[0,], N[1,], N[2,], size=1, marker='point_2d')\n",
    "    ipv.xyzlim(-1.0, 1.5)\n",
    "    ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.radians(-30)\n",
    "T = np.array([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, np.cos(theta), -np.sin(theta), 0],\n",
    "    [0, np.sin(theta), np.cos(theta), 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "X = np.asarray(np.dot(cloud, T))\n",
    "#view_pcl(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter out most of table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_HEIGHT = (0.0, 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,:3]\n",
    "X = pcl.PointCloud(X.astype('float32'))\n",
    "X = X.make_passthrough_filter()\n",
    "X.set_filter_field_name('z')\n",
    "X.set_filter_limits(*TABLE_HEIGHT)\n",
    "X = X.filter()\n",
    "#view_pcl(np.asarray(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = X.make_segmenter()\n",
    "seg.set_model_type(pcl.SACMODEL_PLANE)\n",
    "seg.set_method_type(pcl.SAC_RANSAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers, coefficients = seg.segment()\n",
    "seg.set_distance_threshold(0.1)\n",
    "table = X.extract(inliers, negative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_pcl(np.asarray(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vox = X.make_voxel_grid_filter()\n",
    "LEAF_SIZE = 0.01\n",
    "# Set the voxel (or leaf) size\n",
    "vox.set_leaf_size(LEAF_SIZE, LEAF_SIZE, LEAF_SIZE)\n",
    "downsampled = vox.filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-009fc3e02847>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_MaxClusterSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_SearchMethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tree = X.make_kdtree()\n",
    "ec = X.make_EuclideanClusterExtraction()\n",
    "ec.set_ClusterTolerance(100)\n",
    "ec.set_MinClusterSize(10)\n",
    "ec.set_MaxClusterSize(2500)\n",
    "ec.set_SearchMethod(tree)\n",
    "candidates = ec.Extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
